{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis of 3-target Data with Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/anuragmitra/peax/experiments\n"
     ]
    }
   ],
   "source": [
    "window_size = 3000\n",
    "resolution = 25\n",
    "step_freq = 3\n",
    "genome_size = 12000000\n",
    "num_reads = 1000000\n",
    "targets = 3\n",
    "target_binding_size = 50\n",
    "states = {\n",
    "    \"Background\": 0,\n",
    "    \"BindingA\": 1,\n",
    "    \"BindingB\": 2,\n",
    "    \"BindingC\": 3,\n",
    "    \"BindingAB\": 4,\n",
    "    \"BindingAC\": 5,\n",
    "    \"BindingBC\": 6,\n",
    "    \"BindingABC\": 7,\n",
    "}\n",
    "target_state = 'BindingAB'\n",
    "training_size = 20\n",
    "training_peax_initial_sample_size = 60\n",
    "runs = 5\n",
    "\n",
    "suffix = f'{genome_size}-{num_reads}'\n",
    "step_size = window_size // step_freq\n",
    "\n",
    "bed = f'data/simulated-features-3-targets-{suffix}.bed'\n",
    "bedBed = f'data/simulated-features-3-targets-{suffix}.bigBed'\n",
    "bigwigs = [f'data/signal-target-{t}-distorted-peaks-{suffix}.bigWig' for t in np.arange(3) + 1]\n",
    "\n",
    "import os\n",
    "cwd = os.chdir('experiments')\n",
    "# cwd = os.chdir('simulation')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Background windows: 11976\n",
      "Number of BindingA windows: 69\n",
      "Number of BindingB windows: 73\n",
      "Number of BindingC windows: 54\n",
      "Number of BindingAB windows: 70\n",
      "Number of BindingAC windows: 63\n",
      "Number of BindingBC windows: 78\n",
      "Number of BindingABC windows: 65\n"
     ]
    }
   ],
   "source": [
    "from utils import bed_to_array, chunk_state_array\n",
    "\n",
    "state_array = bed_to_array(bed, genome_size, states)\n",
    "\n",
    "for state in states:\n",
    "    size = 1000 if state == 'Background' else 50\n",
    "    print(f'Number of {state} windows: {(state_array == states[state]).sum()//size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 199 windows with the target\n"
     ]
    }
   ],
   "source": [
    "positive_windows = chunk_state_array(\n",
    "    (state_array == states[target_state]).astype(np.uint8),\n",
    "    window_size,\n",
    "    resolution,\n",
    "    step_size,\n",
    "    (target_binding_size // resolution)\n",
    ")\n",
    "print(f'There are {positive_windows.sum()} windows with the target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 11998 windows from chr1 with a max value of 1.0.\n",
      "Extracted 11998 windows from chr1 with a max value of 1.0.\n",
      "Extracted 11998 windows from chr1 with a max value of 1.0.\n"
     ]
    }
   ],
   "source": [
    "from server.bigwig import chunk\n",
    "\n",
    "windows_signals = []\n",
    "for target in range(targets):\n",
    "    windows_signals.append(chunk(\n",
    "        bigwigs[target],\n",
    "        window_size,\n",
    "        resolution,\n",
    "        step_size,\n",
    "        ['chr1'],\n",
    "        verbose=True,\n",
    "    ))\n",
    "    \n",
    "concat_windows_signals = np.concatenate(windows_signals, axis=1)\n",
    "\n",
    "num_windows = windows_signals[0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double check that the labels are correct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x270 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import plot_windows\n",
    "\n",
    "plot_windows(windows_signals, [np.where(positive_windows == 1)[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, matthews_corrcoef, precision_score, recall_score, roc_auc_score, average_precision_score\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba_ordered(probs, classes_, all_classes=np.array([0,1])):\n",
    "    \"\"\"\n",
    "    probs: list of probabilities, output of predict_proba \n",
    "    classes_: clf.classes_\n",
    "    all_classes: all possible classes (superset of classes_)\n",
    "    \"\"\"\n",
    "    proba_ordered = np.zeros((probs.shape[0], all_classes.size),  dtype=np.float)\n",
    "    sorter = np.argsort(all_classes) # http://stackoverflow.com/a/32191125/395857\n",
    "    idx = sorter[np.searchsorted(all_classes, classes_, sorter=sorter)]\n",
    "    proba_ordered[:, idx] = probs\n",
    "    return proba_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/anuragmitra/peax/experiments/simulation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.chdir('simulation')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode and concat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/anuragmitra/opt/miniconda3/envs/px/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/anuragmitra/opt/miniconda3/envs/px/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from server.encoder import Autoencoder\n",
    "\n",
    "with open('../../examples/autoencoders.json', 'r') as f:\n",
    "    autoencoders = json.load(f)\n",
    "\n",
    "ae_config = autoencoders['histone-mark-chip-seq-3kb'].copy()\n",
    "ae_config['autoencoder_filepath'] = os.path.join('../../', ae_config['autoencoder'])\n",
    "del ae_config['autoencoder']\n",
    "\n",
    "encoder = Autoencoder(**ae_config)\n",
    "\n",
    "# Encode windows\n",
    "encoded_windows_signals = [encoder.encode(x.reshape(*x.shape, 1)) for x in windows_signals]\n",
    "\n",
    "# Concat encoded windows\n",
    "concat_encoded_windows_signals = np.concatenate(encoded_windows_signals, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a representative target and encode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x270 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bbi\n",
    "\n",
    "positive_windows_idx = np.where(positive_windows == 1)[0]\n",
    "\n",
    "search_target_idx = positive_windows_idx[15]\n",
    "\n",
    "search_target_raw = []\n",
    "for windows_signal in windows_signals:\n",
    "    search_target_raw.append(np.concatenate((\n",
    "        windows_signal[search_target_idx][0:120],\n",
    "        windows_signal[search_target_idx + 1][:0],\n",
    "    )).reshape(1, 120))\n",
    "\n",
    "concat_search_target_raw = np.concatenate(search_target_raw, axis=1)\n",
    "concat_search_target_encoded = np.concatenate([encoder.encode(x.reshape(*x.shape, 1)) for x in search_target_raw], axis=1)\n",
    "\n",
    "plot_windows(search_target_raw, [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the distance to the target and knn-neighborhood distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def propagate_labels(\n",
    "    data,\n",
    "    directly_labeled_windows,\n",
    "    window_labels,\n",
    "    window_label_weights,\n",
    "    weight_decay_step: float = 0.95,\n",
    "    weight_decay_pos: float = 0.66,\n",
    "    weight_decay_neg: float = 0.66\n",
    "):\n",
    "    # Temporarily switch negative labels from 0 to -1 for convenience\n",
    "    labeled_window_mask = np.zeros(window_labels.size).astype(bool)\n",
    "    labeled_window_mask[directly_labeled_windows] = True\n",
    "    \n",
    "    # We need to find the 2 nearest neighbors since the node itself is included as the nearest neighbor...\n",
    "    nbrs = NearestNeighbors(n_neighbors=2, n_jobs=-1)\n",
    "    nbrs.fit(data)\n",
    "    \n",
    "    # The first column of `distances` and `indices` is useless as it's always the node itself...\n",
    "    distances, indices = nbrs.kneighbors(data)\n",
    "    \n",
    "    def give_labels(source_windows):\n",
    "        \"\"\"The source windows 'give' their label to their nearest neighbor\"\"\"\n",
    "        nn_of_source_windows = indices[source_windows, 1]\n",
    "        \n",
    "        # ~window_labels[nn_of_source_windows].astype(bool) will be `True` for all windows that do not have a label yet\n",
    "        unlabeled_nn_mask = ~labeled_window_mask[nn_of_source_windows].astype(bool)\n",
    "        num_unlabeled_nn = unlabeled_nn_mask.sum()\n",
    "        \n",
    "        # Unlabeled windows that are the nearest neighbor of the sources\n",
    "        targets = nn_of_source_windows[unlabeled_nn_mask]\n",
    "        # Source windows with an unlabeled nearest neighbors are the sources\n",
    "        sources = source_windows[unlabeled_nn_mask]\n",
    "\n",
    "        # Assign source labels to their nearest neighbor\n",
    "        window_labels[targets] = window_labels[sources]\n",
    "\n",
    "        # Assign weights\n",
    "        window_label_weights[targets] = window_label_weights[sources] * weight_decay_step\n",
    "        \n",
    "        # Determine decay for positively labeled windows\n",
    "        # When nn window is farther away from the target then the source we decay the weight as the chances are higher that it's not a true positive\n",
    "        decay_weight_of_pos_nn = np.logical_and(\n",
    "            window_labels[sources] == 1,\n",
    "            dist_to_target[sources] < dist_to_target[targets]\n",
    "        )\n",
    "        \n",
    "        window_label_weights[targets[decay_weight_of_pos_nn]] *= weight_decay_pos\n",
    "        \n",
    "        # Determine decay for negatively labeled windows\n",
    "        # When nn window is closer to the target then the source we decay the weight as the chances are higher that it's not a true negative\n",
    "        decay_weight_of_neg_nn = np.logical_and(\n",
    "            window_labels[sources] == 0,\n",
    "            dist_to_target[sources] > dist_to_target[targets]\n",
    "        )\n",
    "        \n",
    "        window_label_weights[targets[decay_weight_of_neg_nn]] *= weight_decay_neg\n",
    "        \n",
    "        # Update label mask\n",
    "        labeled_window_mask[targets] = True\n",
    "    \n",
    "        return targets, num_unlabeled_nn\n",
    "    \n",
    "    def take_labels():\n",
    "        \"\"\"The source windows take the label from their nearest neighbors\"\"\"        \n",
    "        unlabeled_windows = np.where(labeled_window_mask == False)[0]\n",
    "        nn_of_unlabeled_windows = indices[unlabeled_windows, 1]\n",
    "        \n",
    "        labeled_nn_mask = labeled_window_mask[nn_of_unlabeled_windows]\n",
    "        num_labeled_nn = labeled_nn_mask.sum()\n",
    "        \n",
    "        # Unlabeled window with a labeled nearest neighbor are the target\n",
    "        targets = unlabeled_windows[labeled_nn_mask]\n",
    "        # Labeled nearest neighbors are the source\n",
    "        sources = nn_of_unlabeled_windows[labeled_nn_mask]\n",
    "\n",
    "        # Assign the label of the nns to the unlabeled source\n",
    "        window_labels[targets] = window_labels[sources]\n",
    "\n",
    "        # Assign weights\n",
    "        window_label_weights[targets] = window_label_weights[sources] * weight_decay_step\n",
    "        \n",
    "        # Determine decay for positively labeled windows\n",
    "        # When nn window is farther away from the target then the source we decay the weight as the chances are higher that it's not a true positive\n",
    "        decay_weight_of_pos_nn = np.logical_and(\n",
    "            window_labels[sources] == 1,\n",
    "            dist_to_target[sources] < dist_to_target[targets]\n",
    "        )\n",
    "        \n",
    "        window_label_weights[targets[decay_weight_of_pos_nn]] *= weight_decay_pos\n",
    "        \n",
    "        # Determine decay for negatively labeled windows\n",
    "        # When nn window is closer to the target then the source we decay the weight as the chances are higher that it's not a true negative\n",
    "        decay_weight_of_neg_nn = np.logical_and(\n",
    "            window_labels[sources] == 0,\n",
    "            dist_to_target[sources] > dist_to_target[targets]\n",
    "        )\n",
    "        \n",
    "        window_label_weights[targets[decay_weight_of_neg_nn]] *= weight_decay_neg\n",
    "        \n",
    "        # Update label mask\n",
    "        labeled_window_mask[targets] = True\n",
    "    \n",
    "        return num_labeled_nn\n",
    "    \n",
    "    windows_with_newly_given_label, num_newly_given_window_labels = give_labels(\n",
    "        np.where(directly_labeled_windows == True)[0]\n",
    "    )\n",
    "    \n",
    "    num_newly_taken_window_labels = take_labels()\n",
    "    \n",
    "    while num_newly_given_window_labels + num_newly_taken_window_labels > 0:\n",
    "        windows_with_newly_given_label, num_newly_given_window_labels = give_labels(windows_with_newly_given_label)\n",
    "    \n",
    "        num_newly_taken_window_labels = take_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric_learn import NCA, LMNN\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from server.sampling import sample_by_dist_density, sample_by_uncertainty_dist_density\n",
    "from server import utils\n",
    "\n",
    "def analyze_al_encoded(\n",
    "    Classifier=lambda: RandomForestClassifier(n_estimators=1000, n_jobs=-1),\n",
    "    classifier_fit=lambda classifier, X, y, weights: classifier.fit(X, y, weights),\n",
    "    max_direct_train_labels=num_windows,\n",
    "    label_prop=False,\n",
    "    label_prop_with_metric_learning=False,\n",
    "    al_with_metric_learning=False,\n",
    "    verbose=False\n",
    "):\n",
    "    if verbose:\n",
    "        print(\"Run started...\")\n",
    "\n",
    "    dist_metric = 'euclidean'\n",
    "\n",
    "    dist_to_target = cdist(concat_encoded_windows_signals, concat_search_target_encoded, dist_metric).flatten()\n",
    "\n",
    "    knn_density = utils.knn_density(concat_encoded_windows_signals)\n",
    "\n",
    "    metrics = {\n",
    "        \"f1\": [],\n",
    "        \"mcc\": [],\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"roc_auc\": [],\n",
    "        \"avg_precision\": [],\n",
    "    }\n",
    "\n",
    "    ml_model = NCA()\n",
    "    \n",
    "    directly_labeled_windows = np.zeros(num_windows).astype(bool)\n",
    "    indirectly_labeled_windows = np.zeros(num_windows).astype(bool)\n",
    "    window_label_weights = np.zeros(num_windows)\n",
    "    window_labels = np.zeros(num_windows).astype(np.uint8)\n",
    "\n",
    "    classifier = Classifier()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    f1_al_encoded = []\n",
    "    mcc_al_encoded = []\n",
    "    precision_al_encoded = []\n",
    "    recall_al_encoded = []\n",
    "    log_loss_al_encoded = []\n",
    "\n",
    "    # First round with our initial sampling strategy\n",
    "    data_selection = ~directly_labeled_windows\n",
    "    data_selection[np.where(concat_windows_signals.max(axis=1) < 0.1)] = False # Filter out almost empty regions\n",
    "\n",
    "    direct_samples = sample_by_dist_density(\n",
    "        concat_encoded_windows_signals,\n",
    "        data_selection,\n",
    "        dist_to_target,\n",
    "        knn_density,\n",
    "        levels=6,\n",
    "        level_sample_size=10,\n",
    "        initial_level_size=20,\n",
    "    )\n",
    "\n",
    "    directly_labeled_windows[direct_samples] = True\n",
    "    window_labels[direct_samples] = positive_windows[direct_samples]\n",
    "    window_label_weights[direct_samples] = 1\n",
    "    \n",
    "    if label_prop_with_metric_learning or al_with_metric_learning:\n",
    "        # Learn Metric\n",
    "        ml_model.fit(\n",
    "            concat_encoded_windows_signals[directly_labeled_windows],\n",
    "            window_labels[directly_labeled_windows]\n",
    "        )\n",
    "\n",
    "    if label_prop:\n",
    "        data_for_label_propagation = concat_encoded_windows_signals\n",
    "        \n",
    "        if label_prop_with_metric_learning:\n",
    "            data_for_label_propagation = ml_model.transform(concat_encoded_windows_signals)\n",
    "            \n",
    "        propagate_labels(\n",
    "            data_for_label_propagation,\n",
    "            directly_labeled_windows,\n",
    "            window_labels,\n",
    "            window_label_weights\n",
    "        )\n",
    "\n",
    "    currently_labeled_windows = np.where(window_label_weights > 0)[0]\n",
    "\n",
    "    classifier_fit(\n",
    "        classifier,\n",
    "        concat_encoded_windows_signals[currently_labeled_windows],\n",
    "        window_labels[currently_labeled_windows],\n",
    "        window_label_weights[currently_labeled_windows]\n",
    "    )\n",
    "\n",
    "    y_pred = classifier.predict(concat_encoded_windows_signals)\n",
    "    prob_pred = predict_proba_ordered(\n",
    "        classifier.predict_proba(concat_encoded_windows_signals),\n",
    "        classifier.classes_\n",
    "    )[:,1]\n",
    "\n",
    "    f1 = f1_score(positive_windows, y_pred)\n",
    "    metrics['f1'].append(f1)\n",
    "\n",
    "    mcc = matthews_corrcoef(positive_windows, y_pred)\n",
    "    metrics['mcc'].append(mcc)\n",
    "\n",
    "    precision = precision_score(positive_windows, y_pred)\n",
    "    metrics['precision'].append(precision)\n",
    "\n",
    "    recall = recall_score(positive_windows, y_pred)\n",
    "    metrics['recall'].append(recall)\n",
    "\n",
    "    avg_precision = average_precision_score(positive_windows, prob_pred)\n",
    "    metrics['avg_precision'].append(avg_precision)\n",
    "\n",
    "    roc_auc = roc_auc_score(positive_windows, prob_pred)\n",
    "    metrics['roc_auc'].append(roc_auc)\n",
    "\n",
    "    dt = (time.time() - start) / 60\n",
    "\n",
    "    if verbose:\n",
    "        print(f'The first round of training with {currently_labeled_windows.size} labels ({directly_labeled_windows.sum()} direct labels) took {dt:.1f} mins.')\n",
    "        print(f'↳ Precision: {precision:.3f} Recall: {recall:.3f} F1: {f1:.3f} MCC: {mcc:.3f} Avg. Precision: {avg_precision:.3f} ROC AUC: {roc_auc:.3f}')\n",
    "        print(f'  ↳ {positive_windows[currently_labeled_windows].sum()} positive labels used')\n",
    "    \n",
    "\n",
    "    # Subsequent round with out active learning sampling strategy\n",
    "    for i in range(directly_labeled_windows.sum(), max_direct_train_labels, training_size):\n",
    "        sample_size = min((~directly_labeled_windows).sum(), training_size)\n",
    "\n",
    "        if al_with_metric_learning:\n",
    "            concat_encoded_windows_signals_transformed = ml_model.transform(concat_encoded_windows_signals)\n",
    "            \n",
    "            direct_samples = sample_by_uncertainty_dist_density(\n",
    "                concat_encoded_windows_signals_transformed,\n",
    "                ~directly_labeled_windows,\n",
    "                cdist(\n",
    "                    concat_encoded_windows_signals_transformed,\n",
    "                    ml_model.transform(concat_search_target_encoded),\n",
    "                    dist_metric\n",
    "                ).flatten(),\n",
    "                utils.knn_density(concat_encoded_windows_signals_transformed),\n",
    "                y_pred,\n",
    "                n=sample_size,\n",
    "            )\n",
    "        else:\n",
    "            direct_samples = sample_by_uncertainty_dist_density(\n",
    "                concat_encoded_windows_signals,\n",
    "                ~directly_labeled_windows,\n",
    "                dist_to_target,\n",
    "                knn_density,\n",
    "                y_pred,\n",
    "                n=sample_size,\n",
    "            )\n",
    "\n",
    "        directly_labeled_windows[direct_samples] = True\n",
    "        window_labels[direct_samples] = positive_windows[direct_samples]\n",
    "        window_label_weights[direct_samples] = 1\n",
    "        \n",
    "        if label_prop_with_metric_learning or al_with_metric_learning:\n",
    "            # Learn Metric\n",
    "            ml_model.fit(\n",
    "                concat_encoded_windows_signals[directly_labeled_windows],\n",
    "                window_labels[directly_labeled_windows]\n",
    "            )\n",
    "\n",
    "        if label_prop:\n",
    "            data_for_label_propagation = concat_encoded_windows_signals\n",
    "            \n",
    "            if label_prop_with_metric_learning:\n",
    "                ml_model.transform(concat_encoded_windows_signals)\n",
    "                \n",
    "            propagate_labels(\n",
    "                data_for_label_propagation,\n",
    "                directly_labeled_windows,\n",
    "                window_labels,\n",
    "                window_label_weights\n",
    "            )\n",
    "\n",
    "        currently_labeled_windows = np.where(window_label_weights > 0)[0]\n",
    "\n",
    "        classifier_fit(\n",
    "            classifier,\n",
    "            concat_encoded_windows_signals[currently_labeled_windows],\n",
    "            window_labels[currently_labeled_windows],\n",
    "            window_label_weights[currently_labeled_windows]\n",
    "        )\n",
    "\n",
    "        y_pred = classifier.predict(concat_encoded_windows_signals)\n",
    "        prob_pred = predict_proba_ordered(\n",
    "            classifier.predict_proba(concat_encoded_windows_signals),\n",
    "            classifier.classes_\n",
    "        )[:,1]\n",
    "\n",
    "        f1 = f1_score(positive_windows, y_pred)\n",
    "        metrics['f1'].append(f1)\n",
    "\n",
    "        mcc = matthews_corrcoef(positive_windows, y_pred)\n",
    "        metrics['mcc'].append(mcc)\n",
    "\n",
    "        precision = precision_score(positive_windows, y_pred)\n",
    "        metrics['precision'].append(precision)\n",
    "\n",
    "        recall = recall_score(positive_windows, y_pred)\n",
    "        metrics['recall'].append(recall)\n",
    "\n",
    "        avg_precision = average_precision_score(positive_windows, prob_pred)\n",
    "        metrics['avg_precision'].append(avg_precision)\n",
    "\n",
    "        roc_auc = roc_auc_score(positive_windows, prob_pred)\n",
    "        metrics['roc_auc'].append(roc_auc)\n",
    "\n",
    "        dt = (time.time() - start) / 60\n",
    "        num_rounds = len(metrics['f1'])\n",
    "\n",
    "        if verbose and directly_labeled_windows.sum() % 100 == 0:\n",
    "            print(f'{num_rounds} rounds of training with {currently_labeled_windows.size} labels ({directly_labeled_windows.sum()} direct labels) took {dt:.1f} mins.')\n",
    "            print(f'↳ Precision: {precision:.3f} Recall: {recall:.3f} F1: {f1:.3f} MCC: {mcc:.3f} Avg. Precision: {avg_precision:.3f} ROC AUC: {roc_auc:.3f}')\n",
    "            print(f'  ↳ {positive_windows[currently_labeled_windows].sum()} positive labels used')\n",
    "    \n",
    "    dt = (time.time() - start) / 60\n",
    "    if verbose:\n",
    "        print(f\"Run ended after {dt:.1f} mins.\")\n",
    "        print(\"\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started...\n",
      "The first round of training with 60 labels (60 direct labels) took 0.0 mins.\n",
      "↳ Precision: 0.383 Recall: 0.387 F1: 0.385 MCC: 0.375 Avg. Precision: 0.314 ROC AUC: 0.864\n",
      "  ↳ 19 positive labels used\n",
      "3 rounds of training with 100 labels (100 direct labels) took 0.0 mins.\n",
      "↳ Precision: 0.461 Recall: 0.327 F1: 0.382 MCC: 0.379 Avg. Precision: 0.320 ROC AUC: 0.828\n",
      "  ↳ 21 positive labels used\n",
      "8 rounds of training with 200 labels (200 direct labels) took 0.1 mins.\n",
      "↳ Precision: 0.557 Recall: 0.342 F1: 0.424 MCC: 0.429 Avg. Precision: 0.368 ROC AUC: 0.814\n",
      "  ↳ 28 positive labels used\n",
      "Run ended after 0.1 mins.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = analyze_al_encoded(\n",
    "    lambda: KNeighborsClassifier(n_jobs=-1),\n",
    "    lambda classifier, X, y, weights: classifier.fit(X, y),\n",
    "    max_direct_train_labels=200,\n",
    "    label_prop=False,\n",
    "    label_prop_with_metric_learning=False,\n",
    "    al_with_metric_learning=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Default\n",
      "↳ RF.......... ↳ Ada.......... ↳ Naive Bayes.......... ↳ KNN.......... done!\n",
      "Run Label Prop.\n",
      "↳ RF."
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dist_to_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-dd0ae081ae7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mclassifiers_fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclassifier_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mmax_direct_train_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             )\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-f511bf319406>\u001b[0m in \u001b[0;36manalyze_al_encoded\u001b[0;34m(Classifier, classifier_fit, max_direct_train_labels, label_prop, label_prop_with_metric_learning, al_with_metric_learning, verbose)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mdirectly_labeled_windows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mwindow_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mwindow_label_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         )\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-26ceef3ade8f>\u001b[0m in \u001b[0;36mpropagate_labels\u001b[0;34m(data, directly_labeled_windows, window_labels, window_label_weights, weight_decay_step, weight_decay_pos, weight_decay_neg)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     windows_with_newly_given_label, num_newly_given_window_labels = give_labels(\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectly_labeled_windows\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     )\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-26ceef3ade8f>\u001b[0m in \u001b[0;36mgive_labels\u001b[0;34m(source_windows)\u001b[0m\n\u001b[1;32m     44\u001b[0m         decay_weight_of_pos_nn = np.logical_and(\n\u001b[1;32m     45\u001b[0m             \u001b[0mwindow_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mdist_to_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mdist_to_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         )\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dist_to_target' is not defined"
     ]
    }
   ],
   "source": [
    "repeats = 10\n",
    "max_direct_train_labels = 200\n",
    "\n",
    "classifiers = {\n",
    "    'RF': lambda: RandomForestClassifier(n_estimators=500, n_jobs=-1),\n",
    "    'Ada': lambda: AdaBoostClassifier(n_estimators=250),\n",
    "    'Naive Bayes': lambda: GaussianNB(),\n",
    "    'KNN': lambda: KNeighborsClassifier(n_jobs=-1),\n",
    "}\n",
    "\n",
    "classifiers_fit = {\n",
    "    'RF': lambda classifier, X, y, weights: classifier.fit(X, y, weights),\n",
    "    'Ada': lambda classifier, X, y, weights: classifier.fit(X, y, weights),\n",
    "    'Naive Bayes': lambda classifier, X, y, weights: classifier.fit(X, y, weights),\n",
    "    'KNN': lambda classifier, X, y, weights: classifier.fit(X, y),\n",
    "}\n",
    "\n",
    "conditions = ['Default', 'Label Prop.', 'Label Prop. with Metric Learning', 'Label Prop. and AL with Metric Learning', 'AL with Metric Learning']\n",
    "conditional_params = [\n",
    "    {},\n",
    "    {\n",
    "        \"label_prop\": True,\n",
    "    },\n",
    "    {\n",
    "        \"label_prop\": True,\n",
    "        \"label_prop_with_metric_learning\": True,\n",
    "    },\n",
    "    {\n",
    "        \"label_prop\": False,\n",
    "        \"label_prop_with_metric_learning\": True,\n",
    "        \"al_with_metric_learning\": True,\n",
    "    },\n",
    "    {\n",
    "        \"al_with_metric_learning\": True,\n",
    "    }\n",
    "]\n",
    "\n",
    "all_results = {}\n",
    "for classifier in classifiers:\n",
    "    all_results[classifier] = {\n",
    "        \"f1\": [],\n",
    "        \"mcc\": [],\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"roc_auc\": [],\n",
    "        \"avg_precision\": [],\n",
    "    }\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i, params in enumerate(conditional_params):\n",
    "    print(f'Run {conditions[i]}')\n",
    "    for classifier_name, Classifier in classifiers.items():\n",
    "        print(f'↳ {classifier_name}', end='')\n",
    "        \n",
    "        for metric in all_results[classifier_name]:\n",
    "            all_results[classifier_name][metric].append([])\n",
    "        \n",
    "        for r in range(repeats):\n",
    "            print(f'.', end='')\n",
    "            results = analyze_al_encoded(\n",
    "                Classifier,\n",
    "                classifiers_fit[classifier_name],\n",
    "                max_direct_train_labels,\n",
    "                **params\n",
    "            )\n",
    "            for metric, value in results.items():\n",
    "                all_results[classifier_name][metric][i].append(value)\n",
    "        print(' ', end='')\n",
    "    print('done!')\n",
    "print(f'Total cross validation took {((time.time()-start)/60):.2f} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_data(values, training_labels=20, intial_training_labels=60, y_label='y'):\n",
    "    data = []\n",
    "\n",
    "    num_runs = len(values)\n",
    "    num_trainings = len(values[0])\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        tmp = np.zeros((num_trainings, 2))\n",
    "        \n",
    "        tmp[0,0] = intial_training_labels\n",
    "        tmp[0,1] = values[run][0]\n",
    "        \n",
    "        tmp[1:,0] = np.arange(1, num_trainings) * training_labels + intial_training_labels\n",
    "        tmp[1:,1] = np.array(values[run])[1:]\n",
    "        \n",
    "        data.append(pd.DataFrame(tmp, columns=['# Labels', y_label]))\n",
    "\n",
    "    return pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    len(all_results['RF']), len(all_results), figsize=(20, 24), gridspec_kw=dict(wspace=0.2, hspace=0.2)\n",
    ")\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "conditions_short = ['None', 'Label Prop.', 'Label Prop. w/ ML', 'Label Prop. & AL w/ ML', 'AL w/ ML']\n",
    "\n",
    "for col, classifier in enumerate(classifiers):\n",
    "    for row, metric in enumerate(all_results[classifier]):\n",
    "        y_max = np.array(all_results[classifier][metric]).max()\n",
    "        y_lim = (0, min(1, y_max + 0.025))\n",
    "        ax = axes[row, col]\n",
    "                  \n",
    "        for condition in range(len(conditions)):\n",
    "            data = get_data(\n",
    "                all_results[classifier][metric][condition],\n",
    "                training_size,\n",
    "                training_peax_initial_sample_size,\n",
    "                y_label=metric\n",
    "            )\n",
    "        \n",
    "            sns.lineplot(\n",
    "                x='# Labels',\n",
    "                y=metric,\n",
    "                data=data,\n",
    "                ax=ax,\n",
    "                label=conditions_short[condition]\n",
    "            )\n",
    "            \n",
    "            ax.set_ylim(y_lim)\n",
    "            \n",
    "        if col > 0:\n",
    "            ax.set_ylabel(None)\n",
    "        if row < 5:\n",
    "            ax.set_xlabel(None)\n",
    "        if row == 0:\n",
    "            ax.set_title(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=4) as pool:\n",
    "    results_new = [pool.apply(analyze_al_encoded) for n in range(runs)]\n",
    "\n",
    "metrics_al_encoded_new = {\n",
    "    \"f1\": [x['f1'] for x in results_new],\n",
    "    \"mcc\": [x['mcc'] for x in results_new],\n",
    "    \"precision\": [x['precision'] for x in results_new],\n",
    "    \"recall\": [x['recall'] for x in results_new],\n",
    "    \"log_loss\": [x['log_loss'] for x in results_new],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/metrics-al-encoded-new.json'):\n",
    "    with open('data/metrics-al-encoded-new.json', 'w') as f:\n",
    "        json.dump(metrics_al_encoded_new, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = []\n",
    "method_names = []\n",
    "metrics = ['f1', 'mcc', 'precision', 'recall', 'log_loss']\n",
    "metric_names = ['F1', 'MCC', 'Precision', 'Recall', 'Log Loss']\n",
    "\n",
    "with open('data/metrics-random-raw.json', 'r') as f:\n",
    "    methods.append(json.load(f))\n",
    "    method_names.append('Random Raw')\n",
    "\n",
    "with open('data/metrics-random-encoded.json', 'r') as f:\n",
    "    methods.append(json.load(f))\n",
    "    method_names.append('Random Encoded')\n",
    "\n",
    "with open('data/metrics-al-encoded-new.json', 'r') as f:\n",
    "    methods.append(json.load(f))\n",
    "    method_names.append('Active Learning Encoded')\n",
    "    \n",
    "fig, axes = plt.subplots(\n",
    "    2,\n",
    "    3,\n",
    "    figsize=(5 * 3, 5 * 2),\n",
    ")\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "for metric_idx, metric in enumerate(metrics):\n",
    "    col = metric_idx // 2\n",
    "    row = metric_idx % 2\n",
    "    \n",
    "    axis = axes[row, col]\n",
    "    axis.set_title(metric_names[metric_idx])\n",
    "    \n",
    "    for method_idx, method in enumerate(methods):\n",
    "        sns.lineplot(\n",
    "            x='x',\n",
    "            y='y',\n",
    "            data=get_data(method[metric], n_first_steps),\n",
    "            ax=axis,\n",
    "            label=None if metric_idx > 0 else method_names[method_idx]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
